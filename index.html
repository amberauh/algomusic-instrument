<body></body>
<script src="https://unpkg.com/tone"></script>
<script src="https://cdn.jsdelivr.net/gh/netizenorg/netnet-standard-library/build/nn.min.js?v=1"></script>
<script src="https://cdn.jsdelivr.net/npm/d3@7"></script>
<script src="https://algorithmicmusic.online/js/create-spectrum.js"></script>
<script src="https://algorithmicmusic.online/js/create-waveform.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
<script>
let detector, video, synth;
let leftHandY = 0;
let rightHandY = 0;
let lastChordIndex = -1; // Track last played chord

const chords = [
  ['C4','E4','G4','B4'], 
  ['Eb4','G4','Bb4','D4'], 
  ['Ab4','C4','Eb4','Gb4'], 
  ['Db4','F4','Ab4','C4'], 
  ['C5','E5','G5','B5']
];

async function setupModel() {
  const model = poseDetection.SupportedModels.BlazePose;
  const detectorConfig = {
    runtime: 'mediapipe',
    solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose'
  };
  return await poseDetection.createDetector(model, detectorConfig);
}

function playChord(chordIndex) {
  if (chordIndex !== lastChordIndex) { 
    synth.releaseAll(); // Stop the previous note
    const volume = nn.map(rightHandY, 0, video.videoHeight, -10, -50); 
    synth.volume.value = volume; 

    // Trigger the new chord and sustain it
    synth.triggerAttack(chords[chordIndex]);
    lastChordIndex = chordIndex;
  }
}

async function update() {
  const poses = await detector.estimatePoses(video);
  const keypoints = poses[0]?.keypoints;

  if (keypoints) {
    leftHandY = keypoints[19]?.y || leftHandY;
    rightHandY = keypoints[20]?.y || rightHandY;

    const chordIndex = Math.floor(nn.map(leftHandY, 0, video.videoHeight, 0, chords.length - 1));

    playChord(chordIndex);
  }

  requestAnimationFrame(update);
}

async function setup() {
  synth = new Tone.PolySynth().toDestination();
  synth.volume.value = -100;

  video = nn.create('video')
    .addTo('body')
    .set({
      autoplay: true,
      muted: true,
      stream: await nn.askFor({ video: true })
    });

  detector = await setupModel();
  
  nn.create('button')
    .content('play instrument')
    .addTo('body')
    .on('click', () => {
      Tone.start(); 
      update();
    });
}

nn.on('load', setup);

</script>