<body></body>
<script src="https://unpkg.com/tone"></script>
<script src="https://cdn.jsdelivr.net/gh/netizenorg/netnet-standard-library/build/nn.min.js?v=1"></script>
<script src="https://cdn.jsdelivr.net/npm/d3@7"></script>
<script src="https://algorithmicmusic.online/js/create-spectrum.js"></script>
<script src="https://algorithmicmusic.online/js/create-waveform.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
<script>
let detector, video, synth;
let leftHandY = 0;
let rightHandY = 0;
let lastChordIndex = -1;

const chords = [
  ['D2','F3','A3','C4','E4'],
  ['A2','G3','Bb3','C#4','F4'], 
  ['F2','E3','G3','A3','D4'], 
  ['C2','E3','G3','B3','D4'], 
  ['G2','F3','A3','B3','E4'], 
  ['D2','F3','A3','C4','E4']
];

let videoHeight = 0; // Variable to store video height dynamically

const chordHeightRange = 0.8; // The percentage of the screen height where chord changes happen (e.g., 80%)

async function setupModel() {
  const model = poseDetection.SupportedModels.BlazePose;
  const detectorConfig = {
    runtime: 'mediapipe',
    solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose'
  };
  return await poseDetection.createDetector(model, detectorConfig);
}

function playChord(chordIndex) {
  if (chordIndex !== lastChordIndex) {
    synth.releaseAll(); // Stop the previous note
    const volume = nn.map(rightHandY, 0, videoHeight, -10, -50); 
    synth.volume.value = volume; 
    synth.triggerAttack(chords[chordIndex]); // Trigger the new chord
    lastChordIndex = chordIndex;
  }
}

async function update() {
  const poses = await detector.estimatePoses(video);
  const keypoints = poses[0]?.keypoints;

  if (keypoints) {
    leftHandY = keypoints[19]?.y || leftHandY;
    rightHandY = keypoints[20]?.y || rightHandY;

    // Dynamically calculate the maxY using the updated videoHeight
    const minY = 0;
    const maxY = videoHeight * chordHeightRange;

    // Map hand position to a reduced range within the middle part of the screen
    const chordIndex = Math.floor(nn.map(leftHandY, minY, maxY, 0, chords.length - 1));

    // Ensure the hand stays within bounds of the selected range (buffer zone)
    if (chordIndex >= 0 && chordIndex < chords.length) {
      playChord(chordIndex);
    }
  }

  requestAnimationFrame(update);
}

async function setup() {
  synth = new Tone.PolySynth().toDestination();
  synth.volume.value = -100;

  // Create the video element and start the camera feed
  video = nn.create('video')
    .addTo('body')
    .set({
      autoplay: true,
      muted: true,
      stream: await nn.askFor({ video: true })
    })
    .on('loadedmetadata', function() {
      // Ensure video height is set after metadata is loaded
      videoHeight = video.clientHeight;
      console.log("Video height:", videoHeight); // Log to ensure it's correctly set
    });

  detector = await setupModel();

  nn.create('button')
    .content('play instrument')
    .addTo('body')
    .on('click', () => {
      Tone.start(); 
      update();
    });
}

nn.on('load', setup);


</script>